# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

---

Для обеспечения процесса разработки с заданными требованиями, я бы порекомендовала использовать облачную систему GitLab.

GitLab - это система контроля версий Git с веб-интерфейсом, которая предоставляет широкие возможности для хранения исходного кода, непрерывной интеграции и поставки.

GitLab предоставляет репозиторий на каждый сервис, что позволяет отслеживать изменения в каждом из них.

GitLab позволяет запускать сборки автоматически по событиям из системы контроля версий и вручную с указанием параметров. Каждой сборке можно привязать свои уникальные настройки.

GitLab также предоставляет создание шаблонов для различных конфигураций сборок и сохранение секретных данных в защищенной форме с использованием «vault».

GitLab позволяет создавать несколько конфигураций для сборки из одного репозитория с использованием кастомных шагов и собственных докер-образов для сборки проектов.

GitLab позволяет развернуть агентов сборки на собственных серверах, что позволяет параллельно запускать несколько сборок и тестов.

В целом, GitLab предоставляет широкие возможности для обеспечения процесса разработки с заданными требованиями и является одним из лучших выборов для облачного хранения и интеграции проектов.


## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

---

Для решения задачи по сбору и анализу логов в микросервисной архитектуре можно использовать такие программные продукты, как ELK-стек или Prometheus + Grafana.

1. ELK-стек (Elasticsearch, Logstash, Kibana):

- Logstash обеспечивает сбор, фильтрацию и пересылку логов от сервисов в центральное хранилище Elasticsearch.
- Elasticsearch является распределенной системой хранения и поиска данных, которая обеспечивает быстрый доступ к логам.
- Kibana предоставляет возможность поиска, фильтрации, визуализации и анализа данных, а также создания пользовательского интерфейса для доступа разработчиков к логам.
- Гарантированную доставку логов можно обеспечить с использованием доставки в потоках через протоколы TCP или UDP.

Для логов можно воспользоваться связкой Elasticsearch + Logstash + Kibana (ELK-стек).
Elastic настраивается как хранилище самих логов, Logstash как сборшик нужных метрик (в купе с модулем metricbeat), а через Kibana можно дать доступ для удобного просмотра и поиска.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

---

Для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре я предлагаю использовать комбинацию следующих программных продуктов: Prometheus, Grafana и Node Exporter.

1. Prometheus: 
Prometheus является мощной системой мониторинга и алертинга, которая может собирать, хранить и анализировать временные ряды метрик. Он предоставляет гибкую модель данных и язык запросов PromQL для извлечения и агрегации информации. Prometheus легко интегрируется с различными сервисами и позволяет собирать метрики как с хостов, так и с приложений.

2. Grafana: 
Grafana предоставляет мощный пользовательский интерфейс для визуализации данных и создания дашбордов. Он позволяет настраивать различные панели для отслеживания состояния системы, включая графики, счетчики, таблицы и т.д. Grafana обладает широким набором инструментов для настройки запросов и агрегации информации, а также предоставляет возможности для создания алертов и уведомлений.

3. Node Exporter:
Node Exporter - это экспортер Prometheus, который собирает метрики о состоянии хостов, включая CPU, RAM, HDD и Network. Он предоставляет встроенные метрики о хостовой машине и позволяет настраивать сбор дополнительных метрик, специфичных для каждого сервиса. Node Exporter является важным компонентом для сбора и анализа метрик состояния ресурсов хостов.

Выбор данной комбинации программных продуктов обоснован следующим образом:

- Prometheus обладает гибкой моделью данных и мощным языком запросов, что позволяет собирать и агрегировать метрики со всех хостов и сервисов в микросервисной архитектуре.
- Grafana предоставляет удобный и гибкий интерфейс для визуализации данных и создания дашбордов, что позволяет настраивать различные панели для отслеживания состояния системы.
- Node Exporter является важным компонентом для сбора метрик состояния ресурсов хостов.

Это решение позволяет собирать метрики со всех хостов и сервисов, обслуживающих систему, а также собирать метрики состояния ресурсов хостов (CPU, RAM, HDD, Network) и потребляемых ресурсов для каждого сервиса. Благодаря гибкому интерфейсу Grafana можно делать запросы, агрегировать информацию и создавать настраиваемые панели для отслеживания состояния системы.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
